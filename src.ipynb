{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rcsb_data = pd.read_csv(\"data/rcsb/RCSB_PDB_Macromolecular_Structure_Dataset_with_Structural_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = rcsb_data.loc[:,[\"Sequence\", \"Number of Residues\", \"Molecular Weight per Deposited Model\", \"Molecular Weight (Entity)\", \"R Free\", \"R Work\", \"Helix\", \"Sheet\", \"Coil\"]]\n",
    "filtered_data = filtered_data.dropna(subset=[\"Helix\", \"Sheet\", \"Coil\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amino_acid_tokenizer(amino_acid : str) -> torch.Tensor:\n",
    "    amino_acid_tokens = {\n",
    "        \"A\": 1,\n",
    "        \"C\": 2,\n",
    "        \"D\": 3,\n",
    "        \"E\": 4,\n",
    "        \"F\": 5,\n",
    "        \"G\": 6,\n",
    "        \"H\": 7,\n",
    "        \"I\": 8,\n",
    "        \"K\": 9,\n",
    "        \"L\": 10,\n",
    "        \"M\": 11,\n",
    "        \"N\": 12,\n",
    "        \"P\": 13,\n",
    "        \"Q\": 14,\n",
    "        \"R\": 15,\n",
    "        \"S\": 16,\n",
    "        \"T\": 17,\n",
    "        \"V\": 18,\n",
    "        \"W\": 19,\n",
    "        \"Y\": 20,\n",
    "        \"X\": 21,\n",
    "        \"U\": 22,\n",
    "        \"O\": 23\n",
    "    }\n",
    "    return torch.tensor([amino_acid_tokens[aa] for aa in amino_acid], dtype = torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data[\"Sequence\"] = filtered_data[\"Sequence\"].apply(amino_acid_tokenizer)\n",
    "\n",
    "# Padding sequences with zeros to make them all the same length\n",
    "max_sequence_length = filtered_data[\"Sequence\"].apply(len).max()\n",
    "filtered_data[\"Sequence\"] = filtered_data[\"Sequence\"].apply(lambda x: torch.nn.functional.pad(x, (0, max_sequence_length - len(x)), \"constant\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambled_data = filtered_data.sample(frac=1)\n",
    "scrambled_data = scrambled_data.reset_index(drop=True)\n",
    "\n",
    "data_size = len(scrambled_data)\n",
    "train_size = int(data_size * 0.8)\n",
    "test_size = data_size - train_size\n",
    "validation_size = int(train_size * 0.2)\n",
    "\n",
    "train_data = scrambled_data.iloc[:train_size - validation_size]\n",
    "validation_data = scrambled_data.iloc[train_size - validation_size:train_size]\n",
    "test_data = scrambled_data.iloc[train_size:]\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "validation_data = validation_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_df = train_data.loc[:,[\"Sequence\", \"Number of Residues\", \"Molecular Weight per Deposited Model\", \"Molecular Weight (Entity)\", \"R Free\", \"R Work\"]]\n",
    "train_output_df = train_data.loc[:,[\"Helix\", \"Sheet\", \"Coil\"]]\n",
    "validation_input_df = validation_data.loc[:,[\"Sequence\", \"Number of Residues\", \"Molecular Weight per Deposited Model\", \"Molecular Weight (Entity)\", \"R Free\", \"R Work\"]]\n",
    "validation_output_df = validation_data.loc[:,[\"Helix\", \"Sheet\", \"Coil\"]]\n",
    "test_input_df = test_data.loc[:,[\"Sequence\", \"Number of Residues\", \"Molecular Weight per Deposited Model\", \"Molecular Weight (Entity)\", \"R Free\", \"R Work\"]]\n",
    "test_output_df = test_data.loc[:,[\"Helix\", \"Sheet\", \"Coil\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input_df, output_df):\n",
    "    input_tensors = torch.tensor(input_df.drop(columns=[\"Sequence\"]).values, dtype=torch.float64)\n",
    "    input_tensor_sequences = torch.stack(tuple(input_df[\"Sequence\"].values), 0)\n",
    "\n",
    "    output_tensors = torch.tensor(output_df.values, dtype=torch.float64)\n",
    "\n",
    "    return torch.utils.data.TensorDataset(input_tensors, input_tensor_sequences, output_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_input_df, train_output_df)\n",
    "validation_dataset = create_dataset(validation_input_df, validation_output_df)\n",
    "test_dataset = create_dataset(test_input_df, test_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch : int,\n",
    "          model : nn.Module,\n",
    "          device: torch.device,\n",
    "          train_dataloader : DataLoader,\n",
    "          optimizer : Optimizer,\n",
    "          loss_fn : nn.Module,\n",
    "          tensorboard_writer : SummaryWriter = None) -> float:\n",
    "    running_loss = 0.\n",
    "\n",
    "    model.train(True)\n",
    "\n",
    "    for idx, (input_tensors, input_tensor_sequences, output_tensors) in enumerate(train_dataloader):\n",
    "        input_tensors = input_tensors.to(device)\n",
    "        input_tensor_sequences = input_tensor_sequences.to(device)\n",
    "        output_tensors = output_tensors.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_tensors, input_tensor_sequences)\n",
    "        loss = loss_fn(output, output_tensors)\n",
    "  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "  \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if tensorboard_writer is not None:\n",
    "            tensorboard_writer.add_scalar(\"Loss/train\", loss.item(), epoch * len(train_dataloader) + idx)\n",
    "\n",
    "    running_loss /= len(train_dataloader)\n",
    "\n",
    "    if tensorboard_writer is not None:\n",
    "        tensorboard_writer.add_scalar(\"Loss/train/epoch\", running_loss, epoch)\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch : int, \n",
    "             model : nn.Module,\n",
    "             device : torch.device,\n",
    "             validation_dataloader : DataLoader,\n",
    "             loss_fn : nn.Module,\n",
    "             tensorboard_writer : SummaryWriter = None) -> float:\n",
    "    running_loss = 0.\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (input_tensors, input_tensor_sequences, output_tensors) in enumerate(validation_dataloader):\n",
    "            input_tensors = input_tensors.to(device)\n",
    "            input_tensor_sequences = input_tensor_sequences.to(device)\n",
    "            output_tensors = output_tensors.to(device)\n",
    "\n",
    "            output = model(input_tensors, input_tensor_sequences)\n",
    "            loss = loss_fn(output, output_tensors)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if tensorboard_writer is not None:\n",
    "                tensorboard_writer.add_scalar(\"Loss/validation\", loss.item(), epoch * len(validation_dataloader) + idx)\n",
    "    \n",
    "    running_loss /= len(validation_dataloader)\n",
    "\n",
    "    if tensorboard_writer is not None:\n",
    "        tensorboard_writer.add_scalar(\"Loss/validation/epoch\", running_loss, epoch)\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model : nn.Module,\n",
    "         device : torch.device,\n",
    "         test_dataloader : DataLoader,\n",
    "         loss_fn : nn.Module) -> float:\n",
    "    running_loss = 0.\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (input_tensors, input_tensor_sequences, output_tensors) in enumerate(test_dataloader):\n",
    "            input_tensors = input_tensors.to(device)\n",
    "            input_tensor_sequences = input_tensor_sequences.to(device)\n",
    "            output_tensors = output_tensors.to(device)\n",
    "\n",
    "            output = model(input_tensors, input_tensor_sequences)\n",
    "            loss = loss_fn(output, output_tensors)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    running_loss /= len(test_dataloader)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model : nn.Module,\n",
    "                device : torch.device,\n",
    "                training_dataloader : DataLoader,\n",
    "                validation_dataloader : DataLoader,\n",
    "                test_dataloader : DataLoader,\n",
    "                optimizer : Optimizer,\n",
    "                loss_fn : nn.Module,\n",
    "                epochs : int,\n",
    "                model_name : str = \"SecondCount\") -> float:\n",
    "    model.to(device)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    tensorboard_writer = SummaryWriter(f\"runs/{model_name}_{timestamp}\")\n",
    "\n",
    "    best_validation_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(epoch, model, device, training_dataloader, optimizer, loss_fn, tensorboard_writer)\n",
    "        validation_loss = validate(epoch, model, device, validation_dataloader, loss_fn, tensorboard_writer)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss} - Validation Loss: {validation_loss}\")\n",
    "\n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            torch.save(model.state_dict(), f\"models/{model_name}_{timestamp}_{epoch}.pt\")\n",
    "\n",
    "\n",
    "    test_loss = test(model, device, test_dataloader, loss_fn)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "    tensorboard_writer.close()\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SecondCount",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
